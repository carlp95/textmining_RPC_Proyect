AbstractThis paper takes a new look at two samplingschemes commonly used to adapt machinelearning algorithms to imbalanced classesand misclassification costs. It uses a perfor-mance analysis technique called cost curvesto explore the interaction of over and under-sampling with the decision tree learner C4.5.C4.5 was chosen as, when combined with oneof the sampling schemes, it is quickly becom-ing the community standard when evaluat-ing new cost sensitive learning algorithms.This paper shows that using C4.5 with under-sampling establishes a reasonable standardfor algorithmic comparison. But it is rec-ommended that the cheapest class classifierbe part of that standard as it can be bet-ter than under-sampling for relatively mod-est costs. Over-sampling, however, shows lit-tle sensitivity, there is often little differencein performance when misclassification costsare changed.